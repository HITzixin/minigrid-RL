episode_reward,value_loss,policy_entropy,fps,explained_variance,episode_length,nupdates,total_timesteps
0,1.7826978364610113e-05,1.9459102153778076,110,-0.1367264986038208,0,1,80
0.018524999916553497,2.8585613108589314e-05,1.9459102153778076,2915,-5.480489253997803,98.775,100,8000
